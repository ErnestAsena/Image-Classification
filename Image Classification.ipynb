{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "Rlp5wUW_FDmH",
    "outputId": "375cb352-57f9-4bc4-aa5b-8a9824e8cad2"
   },
   "outputs": [],
   "source": [
    "# Importing the relevant packages\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining some constants/hyperparameters\n",
    "BUFFER_SIZE = 70_000 # for reshuffling\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Downloading the MNIST dataset\n",
    "\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Extracting the train and test datasets\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Creating a function to scale our image data (it is recommended to scale the pixel values in the range [0,1] )\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining the size of the validation set\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining the size of the test set\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Reshuffling the dataset\n",
    "train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training + validation\n",
    "train_data = train_and_validation_data.skip(num_validation_samples)\n",
    "validation_data = train_and_validation_data.take(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Batching the data\n",
    "# NOTE: For proper functioning of the model, we need to create one big batch for the validation and test sets\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples) \n",
    "test_data = test_data.batch(num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model and training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have preprocessed the dataset, we can define our CNN and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Outlining the model/architecture of our CNN\n",
    "# CONV -> MAXPOOL -> CONV -> MAXPOOL -> FLATTEN -> DENSE\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50, 5, activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
    "    # (2,2) is the default pool size so we could have just used MaxPooling2D() with no explicit arguments\n",
    "    tf.keras.layers.Conv2D(50, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10) # You can apply softmax activation here, see below for comentary\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "___________________________________________________________________________\n",
      "Layer (type)                     Output Shape                  Param #     \n",
      "===========================================================================\n",
      "conv2d (Conv2D)                  (None, 24, 24, 50)            1300        \n",
      "___________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)     (None, 12, 12, 50)            0           \n",
      "___________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 10, 10, 50)            22550       \n",
      "___________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 5, 5, 50)              0           \n",
      "___________________________________________________________________________\n",
      "flatten (Flatten)                (None, 1250)                  0           \n",
      "___________________________________________________________________________\n",
      "dense (Dense)                    (None, 10)                    12510       \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A brief summary of the model and parameters\n",
    "model.summary(line_length = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss function\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Compiling the model with Adam optimizer and the cathegorical crossentropy as a loss function\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'auto',    \n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0, \n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 11:48:59.416447: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 31s 67ms/step - loss: 0.2622 - accuracy: 0.9280 - val_loss: 0.0802 - val_accuracy: 0.9772\n",
      "Epoch 2/20\n",
      "422/422 [==============================] - 30s 68ms/step - loss: 0.0689 - accuracy: 0.9798 - val_loss: 0.0599 - val_accuracy: 0.9810\n",
      "Epoch 3/20\n",
      "422/422 [==============================] - 32s 72ms/step - loss: 0.0517 - accuracy: 0.9847 - val_loss: 0.0468 - val_accuracy: 0.9870\n",
      "Epoch 4/20\n",
      "422/422 [==============================] - 32s 73ms/step - loss: 0.0431 - accuracy: 0.9867 - val_loss: 0.0322 - val_accuracy: 0.9908\n",
      "Epoch 5/20\n",
      "422/422 [==============================] - 32s 73ms/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 0.0321 - val_accuracy: 0.9907\n",
      "Epoch 6/20\n",
      "422/422 [==============================] - 32s 74ms/step - loss: 0.0313 - accuracy: 0.9901 - val_loss: 0.0195 - val_accuracy: 0.9938\n",
      "Epoch 7/20\n",
      "422/422 [==============================] - 33s 75ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.0205 - val_accuracy: 0.9933\n",
      "Epoch 8/20\n",
      "422/422 [==============================] - 33s 75ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.0169 - val_accuracy: 0.9947\n",
      "Epoch 9/20\n",
      "422/422 [==============================] - 33s 77ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 0.0145 - val_accuracy: 0.9957\n",
      "Epoch 10/20\n",
      "422/422 [==============================] - 32s 73ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0171 - val_accuracy: 0.9942\n",
      "Epoch 11/20\n",
      "422/422 [==============================] - 33s 76ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.0096 - val_accuracy: 0.9967\n",
      "Epoch 12/20\n",
      "422/422 [==============================] - 33s 75ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0120 - val_accuracy: 0.9957\n",
      "Epoch 13/20\n",
      "422/422 [==============================] - 33s 74ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0103 - val_accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x165c2c610>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the network\n",
    "model.fit(\n",
    "    train_data, \n",
    "    epochs = NUM_EPOCHS, \n",
    "    callbacks = [early_stopping], \n",
    "    validation_data = validation_data,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFoXl2txFDmV",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0272 - accuracy: 0.9925\n"
     ]
    }
   ],
   "source": [
    "# Testing our model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFoXl2txFDmV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0272. Test accuracy: 99.25%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting images and the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test_data into 2 arrays, containing the images and the corresponding labels\n",
    "for images, labels in test_data.take(1):\n",
    "    images_test = images.numpy()\n",
    "    labels_test = labels.numpy()\n",
    "\n",
    "# Reshape the images into 28x28 form, suitable for matplotlib (original dimensions: 28x28x1)\n",
    "images_plot = np.reshape(images_test, (10000,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB7CAYAAACy7jQ7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEGElEQVR4nO2dTSg8cRyHjbfktRBOJM7KwUtcuEhxc0NKkYOS4kJycZALNi5SUs7KjQNHN0lcnMRBOEgKKYf9X32+23+2aczub/fzeW5Pa3dGj59vM7sz68Xj8RzBR266d0CkB4UnReFJUXhSFJ4UhScl3+9Bz/N0rJfBxONx73+PacWTovCkKDwpCk+KwpOi8KQoPCkKT4rCk6LwpCg8KQpPisKTovCkKDwpCk+KwpOi8KQoPCkKT4rCk6LwpPh+vDrTaW5uBl9YWAAfHx8H9zz8NPLz8zN4b28v+O3tbdhdTBta8aQoPCkKT0pGz/jJyUnwpaUl8Lq6OvD8fPx17d1Anp6ewA8ODnxfb2xsDHxiYgK8r68P/OrqKscVtOJJUXhSFJ6UjJrxm5ub4NPT0+C5ufh3/PDwAH50dAS+t7cHfnd3B/719QVuZ/7w8LDv/nZ2doJrxou0o/CkKDwpTs/4oDP9/v4efGBgADzsufXCwkLfx+25/f39/VDbixKteFIUnhSFJ8XpGT80NARuZ/rh4SH48vIyeNiZPjo6Cj44OAj+8fEBbs/Vf39/h9p+lGjFk6LwpCg8KU7NeDtTa2trwe259pGREfCfn59Q26+qqgKfnZ0FLyoqArfnDY6Pj0NtP5VoxZOi8KQoPClOzfiysjLwvLw88M/PT/CwM93S2NgI3tra+qev7xJa8aQoPCkKT4pTMz4Z9v31/v5+8JOTk0Cv193dDb64uBjo+dvb24F+3iW04klReFI8vy8VTvW3UNXU1IDf3NyAV1dXg7+9vYHPzc2Bv7y8+G5vdXUVvKWlxffn7ce129rawF9fX32fn2r0LVQiAYUnReFJcWrGW6ampsDX19fB7dukUTM/Pw++sbGR0u0HRTNeJKDwpCg8KU6fst3Z2QG3tyOzlynbt1GLi4vB39/ffbdXUVEBbi+Tduky57BoxZOi8KQoPClOH8cHxb7NWlpaCm7Ppa+trYH39PSAX19fg2faR7F0HC8SUHhSFJ4Up4/jg3J+fh7q+fa43Z5HyCa04klReFIUnpSsOo5PRklJCfjp6Sm4vdVKR0dH5PsUJTqOFwkoPCkKT0pWHccnw15y1d7eDn5xcZHK3UkrWvGkKDwpCk8K1Yy3ty8LSkFBAXhlZSV4smv1XEIrnhSFJ0XhSaGa8UEpLy8Hn5mZAbdfQ97U1BT5Pv0VWvGkKDwpCk+KZvwv6uvrwS8vL8EbGhrAt7a2It+nqNCKJ0XhSdG/+l/Y263Zj6XFYjFwe3u1TEIrnhSFJ0XhSaGa8WdnZ+BdXV3gj4+P4CsrK+C7u7vR7Fga0IonReFJUXhSqC6hYkOXUIkEFJ4UhSdF4UlReFIUnhSFJ8X3OF5kL1rxpCg8KQpPisKTovCkKDwp/wAKjOyn1jFfXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 9\n"
     ]
    }
   ],
   "source": [
    "# The image to be displayed and tested\n",
    "i = 600\n",
    "\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_plot[i-1], cmap=\"gray\", aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# Print the correct label for the image\n",
    "print(\"Label: {}\".format(labels_test[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain the model's predictions (logits)\n",
    "predictions = model.predict(images_test[i-1:i])\n",
    "\n",
    "# Convert those predictions into probabilities \n",
    "probabilities = tf.nn.softmax(predictions).numpy()\n",
    "# Convert the probabilities into percentages\n",
    "probabilities = probabilities*100\n",
    "\n",
    "\n",
    "# Create a bar chart to plot the probabilities for each class\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10], height=probabilities[0], tick_label=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model correctly predicts the image to be a 9; and it actually is."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "defaultNotebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
